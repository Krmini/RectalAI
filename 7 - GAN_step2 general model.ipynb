{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tf/data')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MedImageGanFiles.utils import to_gpu, loss_plot, image_grid, create_gif, show_gif\n",
    "from MedImageGanFiles.metrics import FID_plot\n",
    "from MedImageGanFiles.dcgan import weights_init, Generator, training_loop, Discriminator_SN_wide3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'path': '/tf/data/MedImageGanModels/Single slice simple gan.zip',\n",
    "    'images_root_path': '/tf/data/augmented_64_3ch/',\n",
    "    'out': '/tf/data/MedImageGanImages/',\n",
    "    'run': 'MIG3_Wide_img_lr_0_0001_b_16_smooth_5_B_0_9',\n",
    "    'model_save_path': '/tf/data/MedImageGanModels_MyModels/',\n",
    "    'model_save_freq': 500,\n",
    "    'save_discr': True,\n",
    "\n",
    "    'image_size': 64,\n",
    "    'wide_images': True,\n",
    "\n",
    "    'seed': 42,\n",
    "    'n_gpu': 1,\n",
    "\n",
    "    'num_epochs': 30,\n",
    "    'learning_rate': 0.0001,\n",
    "    'beta_adam': 0.9,\n",
    "    'batch_size': 16,\n",
    "    'label_smooth': True,\n",
    "\n",
    "    'latent_vector': 256,\n",
    "\n",
    "    'loader_workers': 2,\n",
    "    'number_channels': 3,\n",
    "    'gen_feature_maps': 64,\n",
    "    'dis_feature_maps': 64\n",
    "    }\n",
    "\n",
    "nz = params['latent_vector']\n",
    "img_path = f\"{params['out']}{params['run']}/\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = to_gpu(ngpu=params['n_gpu'])\n",
    "    print('Cuda available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Cuda NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(netG, wide = False):\n",
    "    fixed_noise = torch.randn(params['image_size'],\n",
    "                            params['latent_vector'], 1, 1, device=device)\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "    plt.figure(figsize=(16,2))\n",
    "    if wide == False:\n",
    "        plt.imshow(np.transpose(vutils.make_grid(fake[:8], padding=2, normalize=True), (1, 2, 0)))\n",
    "    else:\n",
    "        plt.imshow(np.transpose(vutils.make_grid(fake[:3], padding=2, normalize=True, nrow=1), (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(path, batch_size, workers):\n",
    "    def npy_loader(path):\n",
    "        sample = torch.from_numpy(np.load(path))\n",
    "        sample = sample.permute(2,0,1)\n",
    "        return sample\n",
    "\n",
    "    dataset = dset.DatasetFolder(root=path, loader=npy_loader, extensions=['.npy'])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = dataLoader(\n",
    "            path=params['images_root_path'], batch_size=params['batch_size'],\n",
    "            workers=params['loader_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show examples of real data\n",
    "num_images = 5\n",
    "for batch in dataloader:\n",
    "    print(len(batch))\n",
    "    input_data = batch[0]\n",
    "    print(\"Shape of input data:\", input_data.shape)\n",
    "    input_data = input_data[:num_images]\n",
    "    grid_image = vutils.make_grid(input_data, nrow=1, padding=2, normalize=True)\n",
    "    plt.figure(figsize=(20, num_images))\n",
    "    plt.imshow(np.transpose(grid_image, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.title('Navel     <<          Rectum          >>       Legs')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create generator\n",
    "netG = Generator(ngpu=params['n_gpu'], nz=params['latent_vector'],\n",
    "                    ngf=params['gen_feature_maps'], nc=params['number_channels']).to(device)\n",
    "netG.apply(weights_init)\n",
    "netG.load_state_dict(torch.load(params['path']))\n",
    "print('Loaded Generator single channel')\n",
    "input_tensor = torch.randn(1, 256, 1, 1).to(device)\n",
    "print('Output tensor shape:', netG(input_tensor).shape)\n",
    "show_examples(netG)\n",
    "\n",
    "#Modify generator to wide images\n",
    "netG.main[12] = nn.ConvTranspose2d(64, 64, kernel_size=(3, 4), stride=(1, 4), padding=(1, 2), bias=False).apply(weights_init).to(device)\n",
    "netG.main[13] = nn.BatchNorm2d(64).apply(weights_init).to(device)\n",
    "netG.main.add_module('14', nn.ReLU(inplace=True))\n",
    "\n",
    "netG.main.add_module('15', nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=(5, 4), stride=(1, 4), padding=(2,2), bias=False).apply(weights_init).to(device))\n",
    "netG.main.add_module('16', nn.BatchNorm2d(64).to(device))\n",
    "netG.main.add_module('17', nn.ReLU(inplace=True))\n",
    "                     \n",
    "netG.main.add_module('18', nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=(4, 3), stride=(2, 3), padding=(1,2), bias=False).apply(weights_init).to(device))\n",
    "netG.main.add_module('19', nn.Tanh())\n",
    "\n",
    "print('Loaded Generator 23 channels')\n",
    "input_tensor = torch.randn(1, 256, 1, 1).to(device)\n",
    "print('Output tensor shape:', netG(input_tensor).shape)\n",
    "show_examples(netG, wide=True)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create discriminator\n",
    "netD = Discriminator_SN_wide3(params['n_gpu'], nc=params['number_channels'],\n",
    "                        ndf=params['dis_feature_maps']).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 64, 1472).to(device)\n",
    "print(netD(input_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=params['learning_rate'], betas=(\n",
    "    params['beta_adam'], 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=params['learning_rate'], betas=(\n",
    "    params['beta_adam'], 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(params['image_size'],\n",
    "                            params['latent_vector'], 1, 1, device=device)\n",
    "\n",
    "G_losses, D_losses, img_list, img_list_only = training_loop(num_epochs=params['num_epochs'], dataloader=dataloader, wide_images = params['wide_images'],\n",
    "                                                            netG=netG, netD=netD, save_discr=params['save_discr'], device=device, criterion=criterion, nz=params['latent_vector'], smooth = params['label_smooth'],\n",
    "                                                            model_save_path = params['model_save_path']+params['run']+'/', model_save_freq = params['model_save_freq'],\n",
    "                                                            optimizerG=optimizerG, optimizerD=optimizerD, fixed_noise=fixed_noise, out=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(G_losses=G_losses, D_losses=D_losses, out=img_path)\n",
    "FID_plot(real_dataloader = dataloader, generated_img_list = img_list_only, out = img_path)\n",
    "image_grid(dataloader=dataloader, img_list=img_list, wide_images = params['wide_images'],\n",
    "            device=device, out=img_path)\n",
    "gif_path = create_gif(image_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gif(gif_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
