{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tf/data')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from MedImageGanFiles.utils import to_gpu, loss_plot, image_grid\n",
    "from MedImageGanFiles.metrics import FID_plot\n",
    "from MedImageGanFiles.dcgan import weights_init, Generator, Discriminator_SN, training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'path': '/tf/data/MedImageGanModels/netG_lr_100_2.zip',\n",
    "    'images_root_path': '/tf/data/augmented_1slice_64_3ch/',\n",
    "    'out': '/tf/data/MedImageGanImages/',\n",
    "    'run': 'Single_slice_lr_100_b_128_smooth',\n",
    "    'model_save_path': '/tf/data/MedImageGanModels_MyModels/',\n",
    "    'model_save_freq': 500,\n",
    "\n",
    "    'image_size': 64,\n",
    "\n",
    "    'seed': 42,\n",
    "    'n_gpu': 1,\n",
    "\n",
    "    'num_epochs': 15,\n",
    "    'learning_rate': 0.002,\n",
    "    'beta_adam': 0.5,\n",
    "    'batch_size': 128,\n",
    "    'label_smooth': True,\n",
    "\n",
    "    'latent_vector': 256,\n",
    "\n",
    "    'loader_workers': 2,\n",
    "    'number_channels': 3,\n",
    "    'gen_feature_maps': 64,\n",
    "    'dis_feature_maps': 64\n",
    "    }\n",
    "nz = params['latent_vector']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = to_gpu(ngpu=params['n_gpu'])\n",
    "    print('Cuda available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Cuda NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(netG):\n",
    "    fixed_noise = torch.randn(params['image_size'],\n",
    "                            params['latent_vector'], 1, 1, device=device)\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "    plt.figure(figsize=(16,2))\n",
    "    plt.imshow(np.transpose(vutils.make_grid(fake[:8], padding=2, normalize=True), (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(path, batch_size, workers):\n",
    "    def npy_loader(path):\n",
    "        sample = torch.from_numpy(np.load(path))\n",
    "        sample = sample.permute(2,0,1)\n",
    "        return sample\n",
    "\n",
    "    dataset = dset.DatasetFolder(root=path, loader=npy_loader, extensions=['.npy'])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = dataLoader(\n",
    "            path=params['images_root_path'], batch_size=params['batch_size'],\n",
    "            workers=params['loader_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create models\n",
    "netG = Generator(ngpu=params['n_gpu'], nz=params['latent_vector'],\n",
    "                    ngf=params['gen_feature_maps'], nc=params['number_channels']).to(device)\n",
    "\n",
    "netD = Discriminator_SN(params['n_gpu'], nc=params['number_channels'],\n",
    "                        ndf=params['dis_feature_maps']).to(device)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print('Untrained Generator')\n",
    "show_examples(netG)\n",
    "netG.load_state_dict(torch.load(params['path']))\n",
    "print('Loaded Generator')\n",
    "show_examples(netG)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(params['image_size'],\n",
    "                            params['latent_vector'], 1, 1, device=device)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=params['learning_rate'], betas=(\n",
    "    params['beta_adam'], 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=params['learning_rate'], betas=(\n",
    "    params['beta_adam'], 0.999))\n",
    "\n",
    "G_losses, D_losses, img_list, img_list_only = training_loop(num_epochs=params['num_epochs'], dataloader=dataloader,\n",
    "                                                            netG=netG, netD=netD, device=device, criterion=criterion, nz=params['latent_vector'], smooth = params['label_smooth'],\n",
    "                                                            model_save_path = params['model_save_path']+params['run']+'/', model_save_freq = params['model_save_freq'],\n",
    "                                                            optimizerG=optimizerG, optimizerD=optimizerD, fixed_noise=fixed_noise, out=params['out'] + params['run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(G_losses=G_losses, D_losses=D_losses, out=params['out'] + params['run'] + '/')\n",
    "FID_plot(real_dataloader = dataloader, generated_img_list = img_list_only, out = params['out'] + params['run'] + '/')\n",
    "image_grid(dataloader=dataloader, img_list=img_list,\n",
    "            device=device, out=params['out'] + params['run'] + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create GIF of generated image progression\n",
    "anim_file = params['out'] + params['run'] + '/Gan.gif'\n",
    "image_path = Path(params['out'] + params['run'] + '/')\n",
    "filenames = list(image_path.glob('*img.png'))\n",
    "filenames = sorted(filenames)\n",
    "\n",
    "# Function to add progress bar to the image\n",
    "def add_progress_bar(image, progress_percentage):\n",
    "    # Calculate width of the progress bar\n",
    "    progress_width = int(image.shape[1] * progress_percentage / 100)\n",
    "    \n",
    "    # Create a progress bar with the same height and width as the image\n",
    "    progress_bar = np.zeros_like(image)\n",
    "    \n",
    "    # Set color of the progress bar to maximum intensity for the completed portion\n",
    "    progress_bar[:10, :progress_width] = 255\n",
    "    \n",
    "    # Concatenate the progress bar with the image horizontally\n",
    "    image_with_progress = np.concatenate([image, progress_bar], axis=0)\n",
    "    \n",
    "    return image_with_progress\n",
    "\n",
    "# Initialize image writer\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    # Initialize tqdm to create a progress bar\n",
    "    progress_bar = tqdm(total=len(filenames), desc='Creating GIF', unit='image')\n",
    "    \n",
    "    # Iterate through filenames\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        image = imageio.imread(filename)\n",
    "        \n",
    "        # Calculate progress percentage\n",
    "        progress_percentage = int((idx + 1) / len(filenames) * 100)\n",
    "        \n",
    "        # Add progress information to the image\n",
    "        image_with_progress = add_progress_bar(image, progress_percentage)\n",
    "        \n",
    "        # Append image with progress bar to the GIF\n",
    "        for i in range(10):\n",
    "            writer.append_data(image_with_progress)\n",
    "        \n",
    "        # Update progress bar description\n",
    "        progress_bar.set_postfix({'Progress': progress_percentage})\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Finalize progress bar\n",
    "progress_bar.close()\n",
    "print('Gif saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show gif\n",
    "embed.embed_file(anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
